# ğŸ§  Faulty Code Detector

This project uses **machine learning and deep learning models** to detect whether a C program is **faulty or non-faulty** based on its code structure. It leverages static analysis and preprocessed datasets to train predictive models for fault classification.

---

## ğŸ“ Project Structure

```
FAULTY CODE DETECTOR/
â”œâ”€â”€ Datasets/                         # Preprocessed datasets (from PROMISE)
â”‚   â”œâ”€â”€ processed_jm1.csv
â”‚   â””â”€â”€ processed_kc1.csv
â”‚
â”œâ”€â”€ Examples/                         # Example C files
â”‚   â”œâ”€â”€ faulty_example.c
â”‚   â””â”€â”€ non_faulty_example.c
â”‚
â”œâ”€â”€ Model_training/                   # Notebooks for training models
â”‚   â”œâ”€â”€ DL_Models.ipynb
â”‚   â””â”€â”€ ML_Models.ipynb
â”‚
â”œâ”€â”€ models/                           # Trained model files
â”‚   â”œâ”€â”€ ann_model.pth                 # ANN (PyTorch)
â”‚   â”œâ”€â”€ lr_model.pkl                  # Logistic Regression
â”‚   â”œâ”€â”€ meta_model.pth                # Meta model (ensemble)
â”‚   â”œâ”€â”€ nn_model.h5                   # Keras-based neural network
â”‚   â”œâ”€â”€ rf_model.pkl                  # Random Forest
â”‚   â”œâ”€â”€ nn_model.pth                  # Another PyTorch NN variant
â”‚   â”œâ”€â”€ scaler.pkl                    # Scaler used for feature normalization
â”‚   â””â”€â”€ xgb_model.pkl                 # XGBoost model
â”‚
â”œâ”€â”€ data_processing_promise_dataset.py  # Script to process PROMISE datasets
â”œâ”€â”€ Faulty_code_predictor.ipynb         # Final prediction notebook
â”œâ”€â”€ Static_code_analyzer.py             # Extracts code features for prediction
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ README.md                           # Project documentation
```

---

## ğŸ” What It Does

- Extracts **static features** from C code using `Static_code_analyzer.py`
- Loads pre-trained ML/DL models to **predict if code is faulty**
- Uses curated datasets (`jm1`, `kc1`) from the **PROMISE repository**
- Supports **ensemble/meta-learning** using multiple models

---

## ğŸ›  How To Use

### 1. ğŸ”§ Setup Environment

```bash
pip install -r requirements.txt
```

### 2. ğŸ§ª Analyze Example

You can test the system using the sample C files:

```bash
python Static_code_analyzer.py Examples/faulty_example.c
```

Then, use the notebook:

```bash
jupyter notebook Faulty_code_predictor.ipynb
```

This will load the models and predict if the analyzed code is **Faulty** or **Non-Faulty**.

---

## ğŸ“Š Models Used

- Logistic Regression  
- Random Forest  
- XGBoost  
- Neural Networks (Keras + PyTorch)  
- Meta Model (ensemble)

---

## ğŸ“š Datasets

- Based on the **PROMISE repository**
- Processed: `jm1`, `kc1`

---

## ğŸ“„ License

MIT License

---

Let me know if youâ€™d like to add usage screenshots, evaluation metrics, or contribution guidelines!
