{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lizard\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from Static_code_analyzer import static_code_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Load Dataset ======\n",
    "df = pd.read_csv('Datasets/processed_jm1.csv')\n",
    "X = df.drop(\"defects\", axis=1).values\n",
    "y = df[\"defects\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathu\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = joblib.load(\"models/scaler.pkl\")\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ANN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  # last output\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaANN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import models\n",
    "rf_model = joblib.load(\"models/rf_model.pkl\")\n",
    "xgb_model = joblib.load(\"models/xgb_model.pkl\")\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "ann_model = ANN(input_dim)\n",
    "ann_model.load_state_dict(torch.load('models/ann_model.pth'))\n",
    "\n",
    "rnn_model = RNN(input_dim)\n",
    "rnn_model.load_state_dict(torch.load('models/rnn_model.pth'))\n",
    "\n",
    "meta_model = MetaANN()\n",
    "meta_model.load_state_dict(torch.load('models/meta_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacked Hybrid Evaluation on Train Set ===\n",
      "Accuracy: 96.45%\n",
      "Precision: 97.02%\n",
      "Recall: 95.87%\n",
      "F1 Score: 96.44%\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "xgb_pred = xgb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "with torch.no_grad():\n",
    "        ann_pred = torch.sigmoid(\n",
    "            ann_model(torch.tensor(X_train_scaled, dtype=torch.float32))\n",
    "        ).numpy().flatten()\n",
    "        \n",
    "        rnn_pred = torch.sigmoid(\n",
    "            rnn_model(torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1))\n",
    "        ).numpy().flatten()\n",
    "    \n",
    "    # Stack predictions\n",
    "stacked_input = np.vstack((rf_pred, xgb_pred, ann_pred, rnn_pred)).T\n",
    "\n",
    "# Predict using meta-model\n",
    "with torch.no_grad():\n",
    "    meta_output = meta_model(torch.tensor(stacked_input, dtype=torch.float32))\n",
    "    meta_prob = torch.sigmoid(meta_output).numpy().flatten()\n",
    "    meta_prediction = (meta_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the meta-model on Train set\n",
    "print(\"=== Stacked Hybrid Evaluation on Train Set ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, meta_prediction)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_train, meta_prediction)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_train, meta_prediction)*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score(y_train, meta_prediction)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacked Hybrid Evaluation on Test Set ===\n",
      "Accuracy: 96.61%\n",
      "Precision: 96.91%\n",
      "Recall: 96.18%\n",
      "F1 Score: 96.54%\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "xgb_pred = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "with torch.no_grad():\n",
    "        ann_pred = torch.sigmoid(\n",
    "            ann_model(torch.tensor(X_test_scaled, dtype=torch.float32))\n",
    "        ).numpy().flatten()\n",
    "        \n",
    "        rnn_pred = torch.sigmoid(\n",
    "            rnn_model(torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1))\n",
    "        ).numpy().flatten()\n",
    "    \n",
    "    # Stack predictions\n",
    "stacked_input = np.vstack((rf_pred, xgb_pred, ann_pred, rnn_pred)).T\n",
    "\n",
    "# Predict using meta-model\n",
    "with torch.no_grad():\n",
    "    meta_output = meta_model(torch.tensor(stacked_input, dtype=torch.float32))\n",
    "    meta_prob = torch.sigmoid(meta_output).numpy().flatten()\n",
    "    meta_prediction = (meta_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the meta-model on Test set\n",
    "print(\"=== Stacked Hybrid Evaluation on Test Set ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, meta_prediction)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, meta_prediction)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, meta_prediction)*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score(y_test, meta_prediction)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(file_path):\n",
    "    analysis = lizard.analyze_file(file_path)\n",
    "    features = []\n",
    "\n",
    "    for function in analysis.function_list:\n",
    "        n = function.token_count  \n",
    "        v_g = function.cyclomatic_complexity\n",
    "        v = n * np.log2(n + 1) if n > 0 else 0  \n",
    "        d = v / (n + 1) if n > 0 else 1  \n",
    "        i = (1 / d) * v if d > 0 else 0  \n",
    "        e = v * d  \n",
    "        b = v / 3000  \n",
    "        t = e / 18  \n",
    "\n",
    "        comment_lines = 0  # If unavailable, keep at zero\n",
    "        loc_code_and_comment = function.length + comment_lines  \n",
    "\n",
    "        features.append({\n",
    "            \"loc\": function.length,\n",
    "            \"v(g)\": v_g,\n",
    "            \"ev(g)\": max(0, v_g - 1),\n",
    "            \"iv(g)\": max(0, v_g // 2),\n",
    "            \"n\": n,\n",
    "            \"v\": v,\n",
    "            \"l\": 1 / d if d > 0 else 0,\n",
    "            \"d\": d,\n",
    "            \"i\": i,\n",
    "            \"e\": e,\n",
    "            \"b\": b,\n",
    "            \"t\": t,\n",
    "            \"lOCode\": function.length,\n",
    "            \"lOComment\": comment_lines,\n",
    "            \"lOBlank\": 0,\n",
    "            \"locCodeAndComment\": loc_code_and_comment,\n",
    "            \"uniq_Op\": max(1, n // 2),\n",
    "            \"uniq_Opnd\": max(1, n // 2),\n",
    "            \"total_Op\": max(1, n // 2),\n",
    "            \"total_Opnd\": max(1, n // 2),\n",
    "            \"branchCount\": function.fan_out\n",
    "        })\n",
    "\n",
    "    issues = static_code_analyzer(file_path)  # Smart integration\n",
    "    return issues, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_faulty(feature_dict, threshold = 0.5):\n",
    "    input_df = pd.DataFrame([feature_dict])\n",
    "    \n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    \n",
    "    rf_pred = rf_model.predict_proba(input_scaled)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(input_scaled)[:, 1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ann_pred = torch.sigmoid(\n",
    "            ann_model(torch.tensor(input_scaled, dtype=torch.float32))\n",
    "        ).numpy().flatten()\n",
    "        \n",
    "        rnn_pred = torch.sigmoid(\n",
    "            rnn_model(torch.tensor(input_scaled, dtype=torch.float32).unsqueeze(1))\n",
    "        ).numpy().flatten()\n",
    "    \n",
    "    print(f\"RF prediction: {rf_pred[0]*100:.2f}\\nXGB prediction {xgb_pred[0]*100:.2f}\\nANN prediction: {ann_pred[0]*100:.2f}\\nRNN prediction {rnn_pred[0]*100:.2f}\")\n",
    "\n",
    "    stacked_input = np.vstack((rf_pred, xgb_pred, ann_pred, rnn_pred)).T\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        meta_output = meta_model(torch.tensor(stacked_input, dtype=torch.float32))\n",
    "        meta_prob = torch.sigmoid(meta_output).numpy().flatten()[0]\n",
    "        meta_prediction = int(meta_prob > threshold)\n",
    "    \n",
    "    # return \"Faulty\" if final_prediction > threshold else \"Not Faulty\",\n",
    "    return {\n",
    "        \"prediction\": \"Faulty\" if meta_prediction > threshold else \"Not Faulty\",\n",
    "        \"probability\": meta_prob*100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF prediction: 91.00\n",
      "LR prediction 81.91\n",
      "ANN prediction: 89.85\n",
      "RNN prediction 88.88\n",
      "Prediction: Faulty (Fault Probability: 99.93%)\n",
      "\n",
      "RF prediction: 17.00\n",
      "LR prediction 38.23\n",
      "ANN prediction: 14.10\n",
      "RNN prediction 30.69\n",
      "Prediction: Not Faulty (Fault Probability: 0.98%)\n"
     ]
    }
   ],
   "source": [
    "#2142\n",
    "test_input_faulty = {\n",
    "    \"loc\": 122.93905462539,\n",
    "    \"v(g)\": 16.26649839337088,\n",
    "    \"ev(g)\": 8.868012853032942,\n",
    "    \"iv(g)\": 13.532996786741764,\n",
    "    \"n\": 318.00252409943676,\n",
    "    \"v\": 2005.4725250802708,\n",
    "    \"l\": 0.03,\n",
    "    \"d\": 30.07639742939341,\n",
    "    \"i\": 66.78021982918675,\n",
    "    \"e\": 60260.60345429485,\n",
    "    \"b\": 0.666675080331456,\n",
    "    \"t\": 3347.8144516319544,\n",
    "    \"lOCode\": 95.93653052595323,\n",
    "    \"lOComment\": 5.134511246403824,\n",
    "    \"lOBlank\": 19.868012853032944,\n",
    "    \"locCodeAndComment\": 0.0,\n",
    "    \"uniq_Op\": 25.200504819887353,\n",
    "    \"uniq_Opnd\": 54.068517672920294,\n",
    "    \"total_Op\": 189.3350160662912,\n",
    "    \"total_Opnd\": 128.6675080331456,\n",
    "    \"branchCount\": 31.532996786741766\n",
    "}\n",
    "\n",
    "#2100\n",
    "test_input_not_faulty = {\n",
    "    \"loc\": 15.0,\n",
    "    \"v(g)\": 2.0,\n",
    "    \"ev(g)\": 1.0,\n",
    "    \"iv(g)\": 2.0,\n",
    "    \"n\": 53.0,\n",
    "    \"v\": 239.75,\n",
    "    \"l\": 0.21,\n",
    "    \"d\": 4.81,\n",
    "    \"i\": 49.82,\n",
    "    \"e\": 1153.79,\n",
    "    \"b\": 0.08,\n",
    "    \"t\": 64.09,\n",
    "    \"lOCode\": 12.0,\n",
    "    \"lOComment\": 0.0,\n",
    "    \"lOBlank\": 1.0,\n",
    "    \"locCodeAndComment\": 0.0,\n",
    "    \"uniq_Op\": 7.0,\n",
    "    \"uniq_Opnd\": 16.0, \n",
    "    \"total_Op\": 31.0,\n",
    "    \"total_Opnd\": 22.0,\n",
    "    \"branchCount\": 3.0\n",
    "}\n",
    "\n",
    "result_faulty = predict_faulty(test_input_faulty)\n",
    "print(f\"Prediction: {result_faulty['prediction']} (Fault Probability: {result_faulty['probability']:.2f}%)\\n\")\n",
    "result_not_faulty = predict_faulty(test_input_not_faulty)\n",
    "print(f\"Prediction: {result_not_faulty['prediction']} (Fault Probability: {result_not_faulty['probability']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faulty: Static Issues found in the code.\n"
     ]
    }
   ],
   "source": [
    "issues, features = analysis(\"Present/Examples/faulty_example.c\")\n",
    "if not issues:\n",
    "    result = predict_faulty(features[1])\n",
    "    print(f\"Prediction: {result['prediction']} (Fault Probability: {result['probability']:.4f})\")\n",
    "else:\n",
    "    print(\"Faulty: Static Issues found in the code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF prediction: 45.90\n",
      "LR prediction 34.71\n",
      "ANN prediction: 51.80\n",
      "RNN prediction 17.67\n",
      "Prediction: Not Faulty (Fault Probability: 46.4218)\n"
     ]
    }
   ],
   "source": [
    "issues, features = analysis(\"Present/Examples/non_faulty_example.c\")\n",
    "if not issues:\n",
    "    result = predict_faulty(features[1])\n",
    "    print(f\"Prediction: {result['prediction']} (Fault Probability: {result['probability']:.4f})\")\n",
    "else:\n",
    "    print(\"Faulty: Static Issues found in the code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
